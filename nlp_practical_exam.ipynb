{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preparating Logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import logging\n",
        "logging.basicConfig(\n",
        "            format='%(name)s - %(levelname)s: %(message)s', level=logging.DEBUG)\n",
        "logger = logging.getLogger(\"nlp_practical_exam\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Importing The Needed Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fERcWHPBiCbB"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tensorflow - DEBUG: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
            "h5py._conv - DEBUG: Creating converter from 7 to 5\n",
            "h5py._conv - DEBUG: Creating converter from 5 to 7\n",
            "h5py._conv - DEBUG: Creating converter from 7 to 5\n",
            "h5py._conv - DEBUG: Creating converter from 5 to 7\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import gc\n",
        "import pickle\n",
        "\n",
        "try:\n",
        "    import pandas\n",
        "except (ImportError, ModuleNotFoundError) as ex:\n",
        "    logger.error(\"Module pandas not found\")\n",
        "    raise ex(\"Module pandas not found\") from ex\n",
        "\n",
        "try:\n",
        "    import numpy as np\n",
        "except (ImportError, ModuleNotFoundError) as ex:\n",
        "    logger.error(\"Module numpy not found\")\n",
        "    raise ex(\"Module numpy not found\") from ex\n",
        "\n",
        "try:\n",
        "    import pyarabic.araby as araby\n",
        "except (ImportError, ModuleNotFoundError) as ex:\n",
        "    logger.error(\"Module pyarabic not found\")\n",
        "    raise ex(\"Module pyarabic not found\") from ex\n",
        "\n",
        "try:\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "except (ImportError, ModuleNotFoundError) as ex:\n",
        "    logger.error(\"Module sklearn not found\")\n",
        "    raise ex(\"Module sklearn not found\") from ex\n",
        "\n",
        "try:\n",
        "    from keras.preprocessing.text import Tokenizer\n",
        "    from keras.models import load_model\n",
        "except (ImportError, ModuleNotFoundError) as ex:\n",
        "    logger.error(\"Module keras not found\")\n",
        "    raise ex(\"Module keras not found\") from ex\n",
        "\n",
        "try:\n",
        "    import tensorflow\n",
        "    from tensorflow.python.keras import backend\n",
        "    from tensorflow.python.keras.layers import Activation, Dense, Dropout\n",
        "    from tensorflow.python.keras.models import Sequential\n",
        "    from tensorflow.python.keras.utils.np_utils import to_categorical\n",
        "except (ImportError, ModuleNotFoundError) as ex:\n",
        "    logger.error(\"Module tensorflow not found\")\n",
        "    raise ex(\"Module tensorflow not found\") from ex\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WheTh0CIEqI"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ar_reviews_100k.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xuNNPu1oiIoL"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "nlp_practical_exam - INFO: Loading dataset\n"
          ]
        }
      ],
      "source": [
        "logger.info(\"Loading dataset\")\n",
        "dataset = pandas.read_csv(\"ar_reviews_100k.tsv\", sep='\\t', header=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cleaning The Reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQIVT349iJY7",
        "outputId": "8bb4ef15-2e05-40f3-f435-163dc51550e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "nlp_practical_exam - INFO: Preprocessing dataset\n"
          ]
        }
      ],
      "source": [
        "logger.info(\"Preprocessing dataset\")\n",
        "labels = dataset['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Removing Emojis, Links, Mentions, Hashtag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "nlp_practical_exam - INFO: Removing emojis, links, mentions and hashtags\n"
          ]
        }
      ],
      "source": [
        "logger.info(\"Removing emojis, links, mentions and hashtags\")\n",
        "dataset['text'] = dataset['text'].map(lambda text: re.sub(r'[^\\u0600-\\u06ff\\u0750-\\u077f\\ufb50-\\ufbc1\\ufbd3-\\ufd3f\\ufd50-\\ufd8f\\ufd50-\\ufd8f\\ufe70-\\ufefc\\uFDF0-\\uFDFD]+', ' ', text).strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Removing Tashkeel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "nlp_practical_exam - INFO: Removing tashkel\n"
          ]
        }
      ],
      "source": [
        "logger.info(\"Removing tashkel\")\n",
        "dataset['text'] = dataset['text'].map(lambda text: araby.strip_diacritics(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Spliting The Dataset Randomly with Ratio 70%, 30% into Train Data and Test Data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "nlp_practical_exam - INFO: Splitting dataset\n",
            "nlp_practical_exam - INFO: Extracting reviews\n"
          ]
        }
      ],
      "source": [
        "logger.info(\"Splitting dataset\")\n",
        "train_data = dataset.sample(frac=.7)\n",
        "test_data = dataset.drop(labels=train_data.index)\n",
        "#print(f\"Train Data:{len(train_data)}\")\n",
        "#print(f\"Test Data:{len(test_data)}\")\n",
        "logger.info(\"Extracting reviews\")\n",
        "train_reviews = train_data['text']\n",
        "test_reviews = test_data['text']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tokenizing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dzZGt7hQiJcT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "nlp_practical_exam - INFO: Tokenizing reviews\n",
            "nlp_practical_exam - INFO: Collecting garbage\n",
            "nlp_practical_exam - INFO: Collecting garbage\n"
          ]
        }
      ],
      "source": [
        "logger.info(\"Tokenizing reviews\")\n",
        "tokenizer = Tokenizer(num_words=None,lower=False)\n",
        "tokenizer.fit_on_texts(dataset['text'])\n",
        "train_reviews1 = train_reviews[:875]\n",
        "train_reviews2 = train_reviews[875:1750]\n",
        "train_reviews3 = train_reviews[1750:2625]\n",
        "train_reviews4 = train_reviews[2625:3500]\n",
        "train_reviews5 = train_reviews[3500:4375]\n",
        "train_reviews6 = train_reviews[4375:5250]\n",
        "train_reviews7 = train_reviews[5250:6125]\n",
        "train_reviews8 = train_reviews[6125:6999]\n",
        "logger.info(\"Collecting garbage\")\n",
        "del train_reviews\n",
        "gc.collect()\n",
        "tokenized_train1 = tokenizer.texts_to_matrix(train_reviews1, mode='tfidf')\n",
        "tokenized_train2 = tokenizer.texts_to_matrix(train_reviews2, mode='tfidf')\n",
        "tokenized_train3 = tokenizer.texts_to_matrix(train_reviews3, mode='tfidf')\n",
        "tokenized_train4 = tokenizer.texts_to_matrix(train_reviews4, mode='tfidf')\n",
        "tokenized_train5 = tokenizer.texts_to_matrix(train_reviews5, mode='tfidf')\n",
        "tokenized_train6 = tokenizer.texts_to_matrix(train_reviews6, mode='tfidf')\n",
        "tokenized_train7 = tokenizer.texts_to_matrix(train_reviews7, mode='tfidf')\n",
        "tokenized_train8 = tokenizer.texts_to_matrix(train_reviews8, mode='tfidf')\n",
        "test_reviews1 = test_reviews[:750]\n",
        "test_reviews2 = test_reviews[750:1500]\n",
        "test_reviews3 = test_reviews[1500:2250]\n",
        "test_reviews4 = test_reviews[2250:3000]\n",
        "logger.info(\"Collecting garbage\")\n",
        "del test_reviews\n",
        "gc.collect()\n",
        "tokenized_test1 = tokenizer.texts_to_matrix(test_reviews1, mode='tfidf')\n",
        "tokenized_test2 = tokenizer.texts_to_matrix(test_reviews2, mode='tfidf')\n",
        "tokenized_test3 = tokenizer.texts_to_matrix(test_reviews3, mode='tfidf')\n",
        "tokenized_test4 = tokenizer.texts_to_matrix(test_reviews4, mode='tfidf')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Collecting The Unnecessary Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "nlp_practical_exam - INFO: Collecting tokenized reviews\n",
            "nlp_practical_exam - INFO: Collecting garbage\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logger.info(\"Collecting tokenized reviews\")\n",
        "tokenized_train = np.concatenate((tokenized_train1, tokenized_train2, tokenized_train3, tokenized_train4, tokenized_train5, tokenized_train6, tokenized_train7, tokenized_train8), axis=0)\n",
        "tokenized_test = np.concatenate((tokenized_test1, tokenized_test2, tokenized_test3, tokenized_test4))\n",
        "logger.info(\"Collecting garbage\")\n",
        "del tokenized_train1, tokenized_train2, tokenized_train3, tokenized_train4, tokenized_train5, tokenized_train6, tokenized_train7, tokenized_train8\n",
        "del tokenized_test1, tokenized_test2, tokenized_test3, tokenized_test4\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Znxc6crCiJe8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "nlp_practical_exam - INFO: Encoding labels\n",
            "nlp_practical_exam - INFO: Collecting garbage\n",
            "nlp_practical_exam - INFO: Collecting garbage\n",
            "nlp_practical_exam - INFO: Max words: 341256\n"
          ]
        }
      ],
      "source": [
        "logger.info(\"Encoding labels\")\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(labels)\n",
        "labelst=encoder.fit_transform(labels)\n",
        "logger.info(\"Collecting garbage\")\n",
        "del labels\n",
        "num_classes = int((len(set(labelst))))\n",
        "logger.info(\"Collecting garbage\")\n",
        "del labelst\n",
        "gc.collect()\n",
        "encoded_train = encoder.fit_transform(train_data['label'])\n",
        "encoded_test = encoder.fit_transform(test_data['label'])\n",
        "encoded_train= to_categorical(encoded_train,num_classes)\n",
        "#encoded_test = to_categorical(encoded_test, num_classes)\n",
        "num_labels = int(len(encoded_train.shape))\n",
        "max_words = len(tokenizer.word_index) + 1\n",
        "logger.info(f\"Max words: {max_words}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Encoding The Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining The Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VrUaeFiziJlL"
      },
      "outputs": [],
      "source": [
        "def confusion_matrix(true, pred):\n",
        "    \"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\"\"\"\n",
        "    logger.info(\"Computing confusion matrix\")\n",
        "    true_positives = backend.sum(backend.round(backend.clip(true * pred, 0, 1)))\n",
        "    possible_positives = backend.sum(backend.round(backend.clip(true, 0, 1)))\n",
        "    predicted_positives = backend.sum(backend.round(backend.clip(pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + backend.epsilon())\n",
        "    recall = true_positives / (possible_positives + backend.epsilon())\n",
        "    return 2*(precision*recall)/(precision+recall+backend.epsilon())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Building The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KT7RswjSjUj1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "nlp_practical_exam - INFO: Building model\n"
          ]
        }
      ],
      "source": [
        "logger.info(\"Building model\")\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(max_words,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Compiling The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hfNiv5LCjUnM"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['categorical_accuracy','Recall','Precision', confusion_matrix,'TruePositives','TrueNegatives','FalsePositives','FalseNegatives'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training The Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Pretraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "#logger.info(\"Stacking tokenized reviews\")\n",
        "#tokenized_train = np.stack(tokenized_train, axis=0)\n",
        "#encoded_train = np.stack(encoded_train, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "D-3RzayTjUss"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "nlp_practical_exam - INFO: Training model\n",
            "nlp_practical_exam - INFO: Computing confusion matrix\n",
            "tensorflow - WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x1919c1f8dc0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x1919c1f8dc0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "nlp_practical_exam - INFO: Computing confusion matrix\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - ETA: 0s - loss: 0.9778 - categorical_accuracy: 0.5777 - recall: 0.8514 - precision: 0.4342 - confusion_matrix: 0.5755 - true_positives: 5363.0000 - true_negatives: 5609.0000 - false_positives: 6989.0000 - false_negatives: 936.0000"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "nlp_practical_exam - INFO: Computing confusion matrix\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 101s 1s/step - loss: 0.9778 - categorical_accuracy: 0.5777 - recall: 0.8514 - precision: 0.4342 - confusion_matrix: 0.5755 - true_positives: 5363.0000 - true_negatives: 5609.0000 - false_positives: 6989.0000 - false_negatives: 936.0000 - val_loss: 0.9137 - val_categorical_accuracy: 0.6057 - val_recall: 0.8671 - val_precision: 0.4493 - val_confusion_matrix: 0.5919 - val_true_positives: 607.0000 - val_true_negatives: 656.0000 - val_false_positives: 744.0000 - val_false_negatives: 93.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "nlp_practical_exam - INFO: Done training\n"
          ]
        }
      ],
      "source": [
        "logger.info(\"Training model\")\n",
        "history = model.fit(tokenized_train,\n",
        "                    encoded_train,\n",
        "                    batch_size=100,\n",
        "                    epochs=1,\n",
        "                    verbose=\"auto\",\n",
        "                    validation_split=0.1)\n",
        "logger.info(\"Done training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Saving The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "nlp_practical_exam - INFO: Saving model\n",
            "tensorflow - INFO: Assets written to: my_model.h1\\assets\n"
          ]
        }
      ],
      "source": [
        "logger.info(\"Saving model\")\n",
        "model.save('my_model.h1')\n",
        "#del model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Saving The Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "FdiaV7a5jUw0"
      },
      "outputs": [],
      "source": [
        "#with open('tokenizer.pickle', 'wb') as handle:\n",
        "#    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "#with open('tokenizer.pickle', 'rb') as handle:\n",
        "#    tokenizer = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Evaluating The Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "fe error hnaa\n",
        "\n",
        "ValueError: Data cardinality is ambiguous: x sizes: 3000 y sizes: 30000 Make sure all arrays contain the same number of samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "LH4-eWntjU0j"
      },
      "outputs": [],
      "source": [
        "# logger.info(\"Loading model\")\n",
        "# model = load_model('my_model.h1')\n",
        "# logger.info(\"Evaluating model\")\n",
        "#Evaluation_valus = model.evaluate(tokenized_test,encoded_test,verbose=0)\n",
        "#print(\"Loss\" , 'categorical_accuracy','Recall','Precision','confusion_matrix','TruePositives','TrueNegatives','FalsePositives','FalseNegatives')\n",
        "\n",
        "#print(Evaluation_valus)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Showcasing The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "pmGMv_lRkWV-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "nlp_practical_exam - INFO: Predicting random samples\n",
            "c:\\Users\\mohab\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:454: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.5315839  0.9630507  0.05457997]] = \t [1] \t ['Negative']\n",
            "[[0.6127333  0.33929932 0.66454184]] = \t [2] \t ['Positive']\n",
            "[[0.76555943 0.09309551 0.94558156]] = \t [2] \t ['Positive']\n",
            "[[0.93135476 0.284856   0.36489373]] = \t [0] \t ['Mixed']\n",
            "[[0.8375083  0.2819291  0.47313377]] = \t [0] \t ['Mixed']\n",
            "[[0.44984105 0.26952165 0.8521984 ]] = \t [2] \t ['Positive']\n",
            "[[0.57763714 0.5156293  0.46252084]] = \t [0] \t ['Mixed']\n",
            "[[0.65992033 0.29209715 0.72803265]] = \t [2] \t ['Positive']\n",
            "[[0.83567715 0.39372626 0.6170634 ]] = \t [0] \t ['Mixed']\n",
            "[[0.4468559 0.9111206 0.1715954]] = \t [1] \t ['Negative']\n"
          ]
        }
      ],
      "source": [
        "logger.info(\"Predicting random samples\")\n",
        "for review in test_data[\"text\"].sample(n=10):\n",
        "\n",
        "    tokenized_review = tokenizer.texts_to_matrix([review], mode='tfidf')\n",
        "\n",
        "    prediction = model.predict(np.array(tokenized_review))\n",
        "    predicted_class = model.predict_classes(tokenized_review)\n",
        "    predicted_label = encoder.inverse_transform(predicted_class)\n",
        "\n",
        "    print(prediction,\"= \\t\",predicted_class,\"\\t\",predicted_label)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": " nlp_practical_exam.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "601523788c517d7a179e637478d62b7085d568aa1f24d3c6b0da698467f2eecf"
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
