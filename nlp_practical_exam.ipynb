{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fERcWHPBiCbB"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "import string\n",
        "import nltk\n",
        "import keras\n",
        "import sklearn\n",
        "import pickle\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Dense , Activation , Dropout\n",
        "from keras.metrics import Precision , Recall , Accuracy , TruePositives , TrueNegatives , FalsePositives , FalseNegatives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WheTh0CIEqI"
      },
      "source": [
        "# Load Dataset and Mounting Google Drive\n",
        "\n",
        "ar_reviews_100k.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xuNNPu1oiIoL"
      },
      "outputs": [],
      "source": [
        "dataset = pandas.read_csv(\"ar_reviews_100k.tsv\", sep='\\t', header=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNGWnLurRVmG",
        "outputId": "8d761bd6-ef68-467d-b4db-0228b0a7d635"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      label                                               text\n",
            "0  Positive  ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...\n",
            "1  Positive  أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...\n",
            "2  Positive  هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...\n",
            "3  Positive  خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...\n",
            "4  Positive  ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل...\n",
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ],
      "source": [
        "print(dataset.head())\n",
        "print(type(dataset['text']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQIVT349iJY7",
        "outputId": "8bb4ef15-2e05-40f3-f435-163dc51550e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Data:69999\n",
            "Test Data:30000\n"
          ]
        }
      ],
      "source": [
        "labels = dataset['label']\n",
        "reviews = dataset['text']\n",
        "\n",
        "train_data = dataset.sample(frac=.7)\n",
        "test_data = dataset.drop(labels=train_data.index)\n",
        "print(f\"Train Data:{len(train_data)}\")\n",
        "print(f\"Test Data:{len(test_data)}\")\n",
        "\n",
        "train_labels = train_data['label']\n",
        "train_reviews = train_data['text']\n",
        "\n",
        "test_labels =  test_data['label']\n",
        "test_reviews = test_data['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dzZGt7hQiJcT"
      },
      "outputs": [
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 178. GiB for an array with shape (69999, 341256) and data type float64",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\mohab\\Documents\\VSCode\\GitHub\\nlp_practical_exam\\nlp_practical_exam.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mohab/Documents/VSCode/GitHub/nlp_practical_exam/nlp_practical_exam.ipynb#ch0000005?line=0'>1</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m Tokenizer(num_words\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,lower\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mohab/Documents/VSCode/GitHub/nlp_practical_exam/nlp_practical_exam.ipynb#ch0000005?line=1'>2</a>\u001b[0m tokenizer\u001b[39m.\u001b[39mfit_on_texts(reviews)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mohab/Documents/VSCode/GitHub/nlp_practical_exam/nlp_practical_exam.ipynb#ch0000005?line=3'>4</a>\u001b[0m x_train \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39;49mtexts_to_matrix(train_reviews, mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtfidf\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mohab/Documents/VSCode/GitHub/nlp_practical_exam/nlp_practical_exam.ipynb#ch0000005?line=4'>5</a>\u001b[0m x_test \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mtexts_to_matrix(test_reviews, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtfidf\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\mohab\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_preprocessing\\text.py:383\u001b[0m, in \u001b[0;36mTokenizer.texts_to_matrix\u001b[1;34m(self, texts, mode)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/mohab/AppData/Local/Programs/Python/Python310/lib/site-packages/keras_preprocessing/text.py?line=372'>373</a>\u001b[0m \u001b[39m\"\"\"Convert a list of texts to a Numpy matrix.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/mohab/AppData/Local/Programs/Python/Python310/lib/site-packages/keras_preprocessing/text.py?line=373'>374</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/mohab/AppData/Local/Programs/Python/Python310/lib/site-packages/keras_preprocessing/text.py?line=374'>375</a>\u001b[0m \u001b[39m# Arguments\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/mohab/AppData/Local/Programs/Python/Python310/lib/site-packages/keras_preprocessing/text.py?line=379'>380</a>\u001b[0m \u001b[39m    A Numpy matrix.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/mohab/AppData/Local/Programs/Python/Python310/lib/site-packages/keras_preprocessing/text.py?line=380'>381</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/mohab/AppData/Local/Programs/Python/Python310/lib/site-packages/keras_preprocessing/text.py?line=381'>382</a>\u001b[0m sequences \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtexts_to_sequences(texts)\n\u001b[1;32m--> <a href='file:///c%3A/Users/mohab/AppData/Local/Programs/Python/Python310/lib/site-packages/keras_preprocessing/text.py?line=382'>383</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msequences_to_matrix(sequences, mode\u001b[39m=\u001b[39;49mmode)\n",
            "File \u001b[1;32mc:\\Users\\mohab\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_preprocessing\\text.py:413\u001b[0m, in \u001b[0;36mTokenizer.sequences_to_matrix\u001b[1;34m(self, sequences, mode)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/mohab/AppData/Local/Programs/Python/Python310/lib/site-packages/keras_preprocessing/text.py?line=408'>409</a>\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtfidf\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdocument_count:\n\u001b[0;32m    <a href='file:///c%3A/Users/mohab/AppData/Local/Programs/Python/Python310/lib/site-packages/keras_preprocessing/text.py?line=409'>410</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mFit the Tokenizer on some data \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/mohab/AppData/Local/Programs/Python/Python310/lib/site-packages/keras_preprocessing/text.py?line=410'>411</a>\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mbefore using tfidf mode.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> <a href='file:///c%3A/Users/mohab/AppData/Local/Programs/Python/Python310/lib/site-packages/keras_preprocessing/text.py?line=412'>413</a>\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mzeros((\u001b[39mlen\u001b[39;49m(sequences), num_words))\n\u001b[0;32m    <a href='file:///c%3A/Users/mohab/AppData/Local/Programs/Python/Python310/lib/site-packages/keras_preprocessing/text.py?line=413'>414</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, seq \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(sequences):\n\u001b[0;32m    <a href='file:///c%3A/Users/mohab/AppData/Local/Programs/Python/Python310/lib/site-packages/keras_preprocessing/text.py?line=414'>415</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m seq:\n",
            "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 178. GiB for an array with shape (69999, 341256) and data type float64"
          ]
        }
      ],
      "source": [
        "tokenizer = Tokenizer(num_words=None,lower=False)\n",
        "tokenizer.fit_on_texts(reviews)\n",
        "\n",
        "x_train = tokenizer.texts_to_matrix(train_reviews, mode='tfidf')\n",
        "x_test = tokenizer.texts_to_matrix(test_reviews, mode='tfidf')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Znxc6crCiJe8"
      },
      "outputs": [],
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(labels)\n",
        "labelst=encoder.fit_transform(labels)\n",
        "\n",
        "num_classes = int((len(set(labelst))))\n",
        "print((len(set(labelst))))\n",
        "\n",
        "y_train = encoder.fit_transform(train_labels)\n",
        "y_test = encoder.fit_transform(test_labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nI5uRIy3iJhz"
      },
      "outputs": [],
      "source": [
        "y_train= keras.utils.to_categorical(y_train,num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "num_labels = int(len(y_train.shape))\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "max_words=vocab_size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrUaeFiziJlL"
      },
      "outputs": [],
      "source": [
        "\n",
        "def f1_metric(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KT7RswjSjUj1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(max_words,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfNiv5LCjUnM"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['categorical_accuracy','Recall','Precision', f1_metric,'TruePositives','TrueNegatives','FalsePositives','FalseNegatives'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-3RzayTjUss"
      },
      "outputs": [],
      "source": [
        "batch_size = 100\n",
        "epochs = 2\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1)\n",
        "\n",
        "\n",
        "model.save('my_model.h1')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdiaV7a5jUw0"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# saving\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# loading\n",
        "with open('tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LH4-eWntjU0j"
      },
      "outputs": [],
      "source": [
        "#model = keras.models.load_model('my_model.h1')\n",
        "Evaluation_valus = model.evaluate(x_test,y_test,verbose=0)\n",
        "print(\"Loss\" , 'categorical_accuracy','Recall','Precision','f1_metric','TruePositives','TrueNegatives','FalsePositives','FalseNegatives')\n",
        "\n",
        "print(Evaluation_valus)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmGMv_lRkWV-"
      },
      "outputs": [],
      "source": [
        "for x in dataset[\"text\"][:25]:\n",
        "\n",
        "    tokens = tokenizer.reviews_to_matrix([x], mode='tfidf')\n",
        "\n",
        "    c=model.predict(np.array(tokens))\n",
        "    cc=model.predict_classes(tokens)\n",
        "    xc = encoder.inverse_transform(cc)\n",
        "\n",
        "\n",
        "    print(c,\"= \\t\",cc,\"\\t\",xc)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": " nlp_practical_exam.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "601523788c517d7a179e637478d62b7085d568aa1f24d3c6b0da698467f2eecf"
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
