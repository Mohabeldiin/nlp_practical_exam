{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fERcWHPBiCbB"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "import string\n",
        "import nltk\n",
        "import keras\n",
        "import sklearn\n",
        "import time\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from time import time\n",
        "from nltk.corpus import stopwords\n",
        "from pandas import read_csv\n",
        "from pandas.plotting import scatter_matrix\n",
        "from matplotlib import pyplot\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense , Activation , Dropout\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import keras.preprocessing.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuNNPu1oiIoL",
        "outputId": "be151c3b-89f3-4bd6-ed3f-5810ce10bb36"
      },
      "outputs": [],
      "source": [
        "# load dataset\n",
        "dataframe = pandas.read_csv(\"tet.csv\", header=0)\n",
        "dataframe.drop_duplicates(inplace = True)\n",
        "data= dataframe\n",
        "print(dataframe.head())\n",
        "\n",
        "print(type(data['text']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Hdtqqr8iJUS",
        "outputId": "c6038603-8c63-488b-8dfe-61fb2eaf48f7"
      },
      "outputs": [],
      "source": [
        "train_size = int(len(data) * .8)\n",
        "\n",
        "print(int(len(data['text'])))\n",
        "print(train_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQIVT349iJY7"
      },
      "outputs": [],
      "source": [
        "texts= data['text']\n",
        "tags = data['class']\n",
        "\n",
        "\n",
        "train_posts = data['text'][:train_size]\n",
        "train_tags = data['class'][:train_size]\n",
        "\n",
        "\n",
        "\n",
        "test_posts = data['text'][train_size:]\n",
        "test_tags =  data['class'][train_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzZGt7hQiJcT"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=None,lower=False)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "x_train = tokenizer.texts_to_matrix(train_posts, mode='tfidf')\n",
        "x_test = tokenizer.texts_to_matrix(test_posts, mode='tfidf')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Znxc6crCiJe8",
        "outputId": "8e01d50a-fe2b-4d1c-8646-496f6b62e158"
      },
      "outputs": [],
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(tags)\n",
        "tagst=encoder.fit_transform(tags)\n",
        "\n",
        "num_classes = int((len(set(tagst))))\n",
        "print((len(set(tagst))))\n",
        "\n",
        "y_train = encoder.fit_transform(train_tags)\n",
        "y_test = encoder.fit_transform(test_tags)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nI5uRIy3iJhz"
      },
      "outputs": [],
      "source": [
        "y_train= keras.utils.to_categorical(y_train,num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "num_labels = int(len(y_train.shape))\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "max_words=vocab_size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrUaeFiziJlL"
      },
      "outputs": [],
      "source": [
        "import keras.backend as K\n",
        "def f1_metric(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val\n",
        "\n",
        "from keras.metrics import Precision , Recall , Accuracy , TruePositives , TrueNegatives , FalsePositives , FalseNegatives\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KT7RswjSjUj1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(max_words,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfNiv5LCjUnM"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['categorical_accuracy','Recall','Precision', f1_metric,'TruePositives','TrueNegatives','FalsePositives','FalseNegatives'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-3RzayTjUss",
        "outputId": "ab3952da-e6a0-48ed-c06e-0e0942a54d42"
      },
      "outputs": [],
      "source": [
        "batch_size = 100\n",
        "epochs = 2\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1)\n",
        "\n",
        "\n",
        "model.save('my_model.h1')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdiaV7a5jUw0"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# saving\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# loading\n",
        "with open('tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LH4-eWntjU0j",
        "outputId": "98354029-a9af-48fc-bbdc-81b945f5526d"
      },
      "outputs": [],
      "source": [
        "#model = keras.models.load_model('my_model.h1')\n",
        "Evaluation_valus = model.evaluate(x_test,y_test,verbose=0)\n",
        "print(\"Loss\" , 'categorical_accuracy','Recall','Precision','f1_metric','TruePositives','TrueNegatives','FalsePositives','FalseNegatives')\n",
        "\n",
        "print(Evaluation_valus)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmGMv_lRkWV-",
        "outputId": "6b297943-54fd-4c93-b95b-ff3465d4855b"
      },
      "outputs": [],
      "source": [
        "for x in data[\"text\"][:25]:\n",
        "\n",
        "    tokens = tokenizer.texts_to_matrix([x], mode='tfidf')\n",
        "\n",
        "    c=model.predict(np.array(tokens))\n",
        "    cc=model.predict_classes(tokens)\n",
        "    xc = encoder.inverse_transform(cc)\n",
        "\n",
        "\n",
        "    print(c,\"= \\t\",cc,\"\\t\",xc)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled11.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "5914b77f64058c283447d5a8074ae968f7e36af4428f93489237561bdf59b357"
    },
    "kernelspec": {
      "display_name": "Python 3.9.11 32-bit (system)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
